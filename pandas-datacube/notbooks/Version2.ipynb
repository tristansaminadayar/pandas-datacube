{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des différentes statistiques de Dbnary\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data analys \n",
    "import numpy as np\n",
    "\n",
    "#  PLotting\n",
    "import bqplot as bq\n",
    "from ipywidgets import Layout, Box, HBox, VBox\n",
    "\n",
    "\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datetime\n",
    "\n",
    "ENDPOINT: str = \"http://kaiko.getalp.org/sparql\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe qui retourne un DataFrame des résultats d'une requête SPARQL et autes fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load ../../src/SPARQL_query\n",
    "import time as tm\n",
    "from typing import NoReturn\n",
    "\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper\n",
    "from ipywidgets import widgets\n",
    "\n",
    "\n",
    "class SPARQLquery:\n",
    "    \"\"\"\n",
    "    Class allowing to make a query on a remote SPARQL server, its main characteristics are :\n",
    "     - Taking into account the big answers by concatenating them as they are received\n",
    "     - Ability to access the size of the database\n",
    "     - Ability to retrieve the response in `pandas` data frame format\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, endpoint: str, query: str, verbose: bool = False, step: int = 1000,\n",
    "                 widget: widgets.IntProgress = None) -> NoReturn:\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        :param endpoint: Url to the remote SPARQL service\n",
    "        :param query: The query\n",
    "        :param verbose: If the detail text will be displayed\n",
    "        :param step: The max number of result to receive\n",
    "        \"\"\"\n",
    "        self.sparql = SPARQLWrapper(endpoint)\n",
    "        self.sparql.setReturnFormat(\"json\")\n",
    "\n",
    "        self.query: str = query\n",
    "        self.verbose: bool = verbose\n",
    "        self.step: int = step\n",
    "        self.resultSize: int = self.get_result_size()\n",
    "        self.is_widget: bool = False\n",
    "\n",
    "        if widget:\n",
    "            self.widget = widget\n",
    "            self.widget.max = self.resultSize\n",
    "            self.widget.value = 0\n",
    "            self.is_widget = True\n",
    "\n",
    "    def get_result_size(self) -> int:\n",
    "        \"\"\"\n",
    "        Function return the size of a query (only in SELECT query).\n",
    "        \"\"\"\n",
    "\n",
    "        if self.query.strip().startswith(\"SELECT\") or self.query.strip().startswith(\n",
    "                \"select\"):  # Modifie the query to count the number of answer\n",
    "\n",
    "            if self.verbose:\n",
    "                print(tm.strftime(f\"[%H:%M:%S] Obtention du nombre de résultats avant exécuter la requête\"))\n",
    "\n",
    "            start: int = 7  # We detect the position of the first variable after the select\n",
    "            while self.query[start] != '?':\n",
    "                start += 1\n",
    "            end: int = start\n",
    "            while self.query[end:end + 5] != \"WHERE\" and self.query[end:end + 5] != \"where\":\n",
    "                end += 1\n",
    "\n",
    "            mot: str = self.query[start: end - 1]  # THe name of the variable\n",
    "\n",
    "            self.sparql.setQuery(self.query.replace(mot, f\"(COUNT (*) as ?cnt)\", 1))\n",
    "            processed_results: dict = self.sparql.query().convert()  # Do the query\n",
    "            number_of_results: int = int(processed_results['results']['bindings'][0]['cnt']['value'])\n",
    "\n",
    "            if self.verbose:\n",
    "                print(tm.strftime(f\"[%H:%M:%S] Il y a  {number_of_results} résultats...\"))\n",
    "\n",
    "            return number_of_results\n",
    "        return 1\n",
    "\n",
    "    def get_sparql_dataframe(self, query: str, text: str = \"\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Helper function to convert SPARQL results into a Pandas data frame.\n",
    "\n",
    "        Credit: Douglas Fils\n",
    "\n",
    "        :param query: The query to perform\n",
    "        :param text: optional text to print in verbose mode\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            print(tm.strftime(f\"[%H:%M:%S] Transmission {text} en cours...\"), end='')\n",
    "\n",
    "        self.sparql.setQuery(query)\n",
    "\n",
    "        processed_results: dict = self.sparql.query().convert()\n",
    "\n",
    "        if self.verbose:\n",
    "            print(tm.strftime(f\"\\r[%H:%M:%S] Transmission {text} réussi, conversion en Data Frame...\"), end='')\n",
    "\n",
    "        cols = processed_results['head']['vars']\n",
    "\n",
    "        out = [[row.get(c, {}).get('value') for c in cols] for row in processed_results['results']['bindings']]\n",
    "\n",
    "        if self.is_widget:\n",
    "            if text == \"\":\n",
    "                self.widget.value = self.widget.max\n",
    "            else:\n",
    "                self.widget.value = int(text.split(' ')[0])\n",
    "\n",
    "        if self.verbose:\n",
    "            print(tm.strftime(f\" Effectué\"))\n",
    "\n",
    "        return pd.DataFrame(out, columns=cols)\n",
    "\n",
    "    def do_query(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Performs the query all at once if the result is not too big or little by little otherwise,\n",
    "        if the query is not a selection it will be done all at once.\n",
    "\n",
    "        :return: The result of the query\n",
    "        \"\"\"\n",
    "        if self.resultSize > self.step:\n",
    "            query = self.query + f\" LIMIT {self.step}\"\n",
    "            return pd.concat(\n",
    "                [self.get_sparql_dataframe(query + f\" OFFSET {value}\", f\"{value} sur {self.resultSize}\") for value in\n",
    "                 range(0, self.resultSize, self.step)])\n",
    "        return self.get_sparql_dataframe(self.query)\n",
    "\n",
    "\n",
    "def get_datasets(endpoint: str, verbose: bool = False, widget: widgets.IntProgress = None):\n",
    "    \"\"\"\n",
    "    Dbnary specific function;\n",
    "\n",
    "    Get all datasets available names on Dbnary and their description.\n",
    "\n",
    "    :param endpoint: The address of the SPARQL server\n",
    "    :param verbose: If the detail text will be displayed\n",
    "    :param widget: If the detail widget will be displayed\n",
    "    :return: The data frame of all datasets available names and their description\n",
    "    \"\"\"\n",
    "\n",
    "    query: str = \"SELECT ?dataset ?commentaire WHERE {?dataset a qb:DataSet ; rdfs:comment ?commentaire}\"\n",
    "\n",
    "    if verbose:\n",
    "        print(tm.strftime(f\"[%H:%M:%S] Requête au serveur des différents datasets disponible... \"))\n",
    "\n",
    "    list_datasets: pd.DataFrame = SPARQLquery(endpoint, query, verbose=verbose,\n",
    "                                              widget=widget).do_query()  # We recovers all DataSets Structure\n",
    "\n",
    "    if verbose:\n",
    "        print(tm.strftime(f\"[%H:%M:%S] Il y a {len(list_datasets)} datasets disponibles\"))\n",
    "\n",
    "    return list_datasets\n",
    "\n",
    "\n",
    "def get_features(endpoint: str, dataset_name: str, widget: widgets.IntProgress = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Dbnary specific function;\n",
    "\n",
    "    Get all features available names on a dataset in Dbnary.\n",
    "\n",
    "    :param endpoint: The address of the SPARQL server\n",
    "    :param dataset_name: The name of the dataset where you want to have its features\n",
    "    :param widget: If the detail widget will be displayed\n",
    "    :return: The data frame of all datasets features names available\n",
    "    \"\"\"\n",
    "    query: str = f\"\"\"DESCRIBE ?item WHERE {'{'} ?item qb:dataSet <{dataset_name}> {'}'} LIMIT 1\"\"\"\n",
    "    result: pd.DataFrame = SPARQLquery(endpoint, query, widget=widget).do_query()\n",
    "    return result['p'].to_frame(name=None).set_axis([\"Caractéristiques\"], axis=1)\n",
    "\n",
    "\n",
    "def download_dataset(endpoint: str, dataset_name: str, features_names: list[str],\n",
    "                     widget: widgets.IntProgress = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Dbnary specific function;\n",
    "\n",
    "    Download and return all selected features of a dataset\n",
    "\n",
    "    :param endpoint: The address of the SPARQL server\n",
    "    :param dataset_name: The name of the dataset where you want to download its features\n",
    "    :param features_names: The names of features to download\n",
    "    :param widget: If the detail widget will be displayed\n",
    "    :return: The data frame of selected and downloaded characteristics of a dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # We will build the query\n",
    "    query: str = \"SELECT \"\n",
    "    vars_list: list[str] = [item.split('#')[-1] for item in features_names]\n",
    "    for item in vars_list:\n",
    "        query += f\"?{item} \"\n",
    "    query += f\"WHERE {'{'} ?o qb:dataSet <{dataset_name}> . \"\n",
    "    for uri, name in zip(features_names, vars_list):\n",
    "        query += f\"?o <{uri}> ?{name} . \"\n",
    "    query += \"} \"\n",
    "\n",
    "    # Do the query\n",
    "    return SPARQLquery(endpoint, query, widget=widget).do_query()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On commence par chercher tout les différents types de datasets et on va proposer à l'utilisateur de choisir quel dataset télécharger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, bar_style='success', description='Loading:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Veuillez choisir un DataSet à étudier: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71b01862f0040b6984cfd0211156dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Box(children=(Dropdown(description='Choix:', layout=Layout(flex='1 3 auto', width='auto'), opti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8a45c2a96145ca9530217c207271bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ui = widgets.IntProgress(bar_style='success', description='Loading:',)\n",
    "display(ui)\n",
    "list_datasets = get_datasets(ENDPOINT, verbose = False, widget = ui)\n",
    "ui.close()\n",
    "list_datasets_short = list_datasets['dataset'].map(lambda x: x.split('/')[-1]).to_frame().join(list_datasets['commentaire'].to_frame())\n",
    "\n",
    "DataFrame = pd.DataFrame()\n",
    "output = widgets.Output()\n",
    "\n",
    "dataset_user_choice = widgets.Dropdown(options = [(name, full_name) for name, full_name in zip(list_datasets_short['dataset'].values.reshape(-1),\n",
    "                                                                                               list_datasets['dataset'].values.reshape(-1))], \n",
    "                                       description=\"Choix:\", layout=Layout(flex='1 3 auto', width='auto'))\n",
    "user_choice_confirm = widgets.Button(description='Soumettre', icon='check', layout=Layout(flex='1 1 auto', width='auto'),\n",
    "                                     tooltip = \"Cliquer ici pour confirmer votre choix\")\n",
    "description = widgets.Label(value=f\"Description: {list_datasets[list_datasets['dataset'] == dataset_user_choice.value]['commentaire'].values[0]}\",\n",
    "                            layout=Layout(flex='1 1 auto', width='auto'))\n",
    "\n",
    "items = [dataset_user_choice, user_choice_confirm]\n",
    "\n",
    "box_layout = Layout(display='flex', flex_flow='row', align_items='stretch', width='90%')\n",
    "                            \n",
    "line_1 = Box(children=items, layout=box_layout)\n",
    "line_2 = Box(children=[description], layout=box_layout)\n",
    "ui = VBox([line_1, line_2])\n",
    "\n",
    "def user_choice_change(obj):\n",
    "    description.value=f\"Description: {list_datasets[list_datasets['dataset'] == dataset_user_choice.value]['commentaire'].values[0]}\"\n",
    "\n",
    "\n",
    "def user_choice_confirm_eventhandler(obj):\n",
    "    choice: str = dataset_user_choice.value\n",
    "    with output:\n",
    "        clear_output()\n",
    "        output2 = widgets.Output()\n",
    "        display(Markdown(data=\"#### Les différentes catégories de ce dataset sont: \"))\n",
    "        progress_bar = widgets.IntProgress(bar_style='success', description='Loading:')\n",
    "        display(progress_bar)\n",
    "        categories_long = get_features(ENDPOINT, choice)\n",
    "        categories_short = categories_long[\"Caractéristiques\"].map(lambda x: x.split('#')[-1]).to_frame()\n",
    "        progress_bar.close()\n",
    "        \n",
    "        display(categories_short)\n",
    "        \n",
    "        select = widgets.SelectMultiple(options=[(name, full_name) for name, full_name in zip(categories_short.values.reshape(-1), categories_long.values.reshape(-1))], \n",
    "                                        description='Critères: ', disabled=False, layout=Layout(flex='1 1 auto', width='auto', height = \"auto\"),\n",
    "                                        style={'description_width': 'initial'})\n",
    "        select_box = Box(children=[select], layout=box_layout)\n",
    "        display(Markdown(\"####  Veuillez choisir au moins deux critères à télécharger:\"))\n",
    "        select_confirm = widgets.Button(description='Soumettre', icon='check', layout=Layout(flex='1 1 auto', width='auto'),\n",
    "                                     tooltip = \"Cliquer ici pour confirmer votre choix\")\n",
    "        select_confirm_box = Box(children=[select_confirm], layout=box_layout)\n",
    "        select_ui = VBox([select_box, select_confirm_box])\n",
    "        \n",
    "        def selection_confirm_eventhandler(obj):\n",
    "            with output2:\n",
    "                if len(select.value) >= 2: # We will constuct the query\n",
    "                    global DataFrame\n",
    "                    clear_output()\n",
    "                    progress_bar = widgets.IntProgress(bar_style='success', description='Loading:')\n",
    "                    display(progress_bar)\n",
    "                    DataFrame = download_dataset(ENDPOINT, choice, select.value, progress_bar)\n",
    "                    progress_bar.close()\n",
    "                    display(DataFrame.head())                 \n",
    "            \n",
    "        select_confirm.on_click(selection_confirm_eventhandler)\n",
    "        display(select_ui, output2)\n",
    "        \n",
    "        \n",
    "user_choice_confirm.on_click(user_choice_confirm_eventhandler)\n",
    "dataset_user_choice.observe(user_choice_change, 'value')\n",
    "\n",
    "display(Markdown(data=\"#### Veuillez choisir un DataSet à étudier: \"))\n",
    "display(ui, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des certains Data set particulier, le code ci-dessous n'est pas généralisable\n",
    "#### 1. dbnaryNymRelationsCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1640da08fe94492950b00ae5311ecd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Choix:', options=(('Statistiques globales', 'glob'), ('Par pays', 'pays')), tooltip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00dfd3940a348e4ace2e48c9d0eb461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DataFrame['count'] = DataFrame['count'].astype(int)\n",
    "\n",
    "relations = DataFrame['nymRelation'].unique()\n",
    "labels = [item.split('#')[-1] for item in relations]\n",
    "data1 = DataFrame.pivot_table(columns='nymRelation', index = ['wiktionaryDumpVersion', 'observationLanguage'], aggfunc=lambda x: max(x)).reset_index().sort_values(by='observationLanguage').sort_values(by='wiktionaryDumpVersion')\n",
    "\n",
    "def transformation_date(date: int) -> datetime.datetime:\n",
    "    if int(date[6:]) == 0:\n",
    "        return datetime.datetime(year=int(date[:4]), month=int(date[4:6]), day=int(date[6:]) + 1)\n",
    "    return datetime.datetime(year=int(date[:4]), month=int(date[4:6]), day=int(date[6:]))\n",
    "\n",
    "data1[\"wiktionaryDumpVersion\"] = data1[\"wiktionaryDumpVersion\"].map(transformation_date)\n",
    "\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "choice = widgets.ToggleButtons(options=[('Statistiques globales', 'glob'), ('Par pays', 'pays')],  description='Choix:',\n",
    "    disabled=False,\n",
    "    tooltips=['Statistiques de tout les pays par années', 'Statistiques d\\' pays au cours du temps']\n",
    ")\n",
    "\n",
    "def event(obj):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        if choice.value == \"pays\":\n",
    "            user_choice = widgets.Dropdown(options = list(data1[\"observationLanguage\"].unique()), description=\"Choix:\")\n",
    "\n",
    "            choosed_data = data1[data1[\"observationLanguage\"] == user_choice.value]\n",
    "\n",
    "            y_sc = bq.LinearScale()\n",
    "            x_ord = bq.scales.DateScale()\n",
    "            \n",
    "            line = bq.Lines(x=choosed_data[\"wiktionaryDumpVersion\"] , y=choosed_data[\"count\"][relations].T, stroke_width=1, display_legend=True, labels= labels, scales={'x': x_ord, 'y': y_sc})\n",
    "            ax_x = bq.Axis(scale=x_ord, grid_lines='solid', label='Date', tick_format = '%m %Y' , tick_style = {'font-size': 18})\n",
    "            ax_y = bq.Axis(scale=y_sc, orientation='vertical', grid_lines='solid', label='Valeur', label_offset='-50')\n",
    "            fig = bq.Figure(marks=[line], axes=[ax_x, ax_y], title=f\"Différentes relations lexicales dans l'extraction {user_choice.value}\", animation_duration = 1000)\n",
    "\n",
    "            def edit_graph(obj):\n",
    "                choosed_data = data1[data1[\"observationLanguage\"] == user_choice.value]\n",
    "                line.y = choosed_data[\"count\"][relations].T\n",
    "                line.x = choosed_data[\"wiktionaryDumpVersion\"]\n",
    "                fig.title = f\"Différentes relations lexicales dans l'extraction {user_choice.value}\"\n",
    "            \n",
    "        if choice.value == \"glob\":\n",
    "            user_choice = widgets.Dropdown(options = [(np.datetime_as_string(item, unit='D'), item) for item in data1[\"wiktionaryDumpVersion\"].unique()], description=\"Choix:\", value = max(data1[\"wiktionaryDumpVersion\"].unique()))\n",
    "            \n",
    "            x_ord = bq.OrdinalScale()\n",
    "            y_sc = bq.LinearScale()\n",
    "            \n",
    "            choosed_data = data1[data1[\"wiktionaryDumpVersion\"] == user_choice.value]\n",
    "            \n",
    "            x = choosed_data[\"observationLanguage\"].values\n",
    "            y = choosed_data[\"count\"][relations].T\n",
    "            \n",
    "            bar = bq.Bars(x=x, y=y, scales={'x': x_ord, 'y':y_sc}, type='stacked', labels = labels, color_mode = 'element', display_legend=True,  colors =[\"red\", \"blue\", \"cyan\", \"pink\", \"lime\", \"purple\", \"orange\", \"brown\"])\n",
    "            ax_x = bq.Axis(scale=x_ord, grid_lines='solid', label='Pays', tick_style = {'font-size': 18})\n",
    "            ax_y = bq.Axis(scale=y_sc, orientation='vertical', grid_lines='solid', label='Valeur', label_offset='-50')\n",
    "            fig = bq.Figure(marks=[bar], axes=[ax_x, ax_y], title=f\"Nombre de relations lexicales dans l'extraction du {np.datetime_as_string(user_choice.value, unit='D')}\", animation_duration = 1000)\n",
    "            \n",
    "            def edit_graph(obj):\n",
    "                choosed_data = data1[data1[\"wiktionaryDumpVersion\"] == user_choice.value]\n",
    "                bar.x = choosed_data[\"observationLanguage\"].values\n",
    "                bar.y = choosed_data[\"count\"][relations].T\n",
    "                fig.title = f\"Nombre de relations lexicales dans l'extraction du {np.datetime_as_string(user_choice.value, unit='D')}\"\n",
    "            \n",
    "        display(user_choice)\n",
    "        user_choice.observe(edit_graph,'value')\n",
    "        display(fig)  \n",
    "    \n",
    "choice.observe(event, 'value')\n",
    "display(choice, out)\n",
    "event(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. dbnaryStatisticsCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42cc6ae8df247968e6656c1312b8ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Choix:', options=(('Statistiques globales', 'glob'), ('Par pays', 'pays')), tooltip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d14cec767545fdb8f4e33613234744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categories = [\"lexicalEntryCount\", \"translationsCount\", \"lexicalSenseCount\", \"pageCount\"]\n",
    "\n",
    "data2 = DataFrame.sort_values(by='wiktionaryDumpVersion')\n",
    "data2[categories] = data2[categories].astype(int)\n",
    "\n",
    "def transformation_date(date: int) -> datetime.datetime:\n",
    "    if int(date[6:]) == 0:\n",
    "        return datetime.datetime(year=int(date[:4]), month=int(date[4:6]), day=int(date[6:]) + 1)\n",
    "    return datetime.datetime(year=int(date[:4]), month=int(date[4:6]), day=int(date[6:]))\n",
    "\n",
    "data2[\"wiktionaryDumpVersion\"] = data2[\"wiktionaryDumpVersion\"].map(transformation_date)\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "choice = widgets.ToggleButtons(options=[('Statistiques globales', 'glob'), ('Par pays', 'pays')],  description='Choix:',\n",
    "    disabled=False,\n",
    "    tooltips=['Statistiques de tout les pays par années', 'Statistiques d\\' pays au cours du temps']\n",
    ")\n",
    "\n",
    "def event(obj):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        if choice.value == \"pays\":\n",
    "            user_choice = widgets.Dropdown(options = list(data1[\"observationLanguage\"].unique()), description=\"Choix:\")\n",
    "\n",
    "            choosed_data = data2[data2[\"observationLanguage\"] == user_choice.value]\n",
    "\n",
    "            y_sc = bq.LinearScale()\n",
    "            x_ord = bq.scales.DateScale()\n",
    "\n",
    "            line = bq.Lines(x=choosed_data[\"wiktionaryDumpVersion\"] , y=choosed_data[categories].T, stroke_width=1, display_legend=True, labels=categories, scales={'x': x_ord, 'y': y_sc})\n",
    "            ax_x = bq.Axis(scale=x_ord, grid_lines='solid', label='Date', tick_format = '%m %Y', tick_style = {'font-size': 18})\n",
    "            ax_y = bq.Axis(scale=y_sc, orientation='vertical', grid_lines='solid', label='Valeur', label_offset='-50')\n",
    "            fig = bq.Figure(marks=[line], axes=[ax_x, ax_y], title=f\"Nombre d'éléments dans l'extraction {user_choice.value}\", animation_duration = 1000)\n",
    "\n",
    "            def edit_graph(obj):\n",
    "                choosed_data = data2[data2[\"observationLanguage\"] == user_choice.value]\n",
    "                line.y = choosed_data[categories].T\n",
    "                line.x = choosed_data[\"wiktionaryDumpVersion\"]\n",
    "                \n",
    "        if choice.value == \"glob\":\n",
    "            user_choice = widgets.Dropdown(options = [(np.datetime_as_string(item, unit='D'), item) for item in data1[\"wiktionaryDumpVersion\"].unique()], description=\"Choix:\", value = max(data1[\"wiktionaryDumpVersion\"].unique()))\n",
    "            \n",
    "            x_ord = bq.OrdinalScale()\n",
    "            y_sc = bq.LinearScale()\n",
    "            \n",
    "            choosed_data = data2[data2[\"wiktionaryDumpVersion\"] == user_choice.value]\n",
    "            \n",
    "            x = choosed_data[\"observationLanguage\"].values\n",
    "            y = choosed_data[categories].T\n",
    "            \n",
    "            bar = bq.Bars(x=x, y=y, scales={'x': x_ord, 'y':y_sc}, type='stacked', labels = categories, color_mode = 'element', display_legend=True,  colors =[\"red\", \"blue\", \"cyan\", \"pink\", \"lime\", \"purple\", \"orange\", \"brown\"])\n",
    "            ax_x = bq.Axis(scale=x_ord, grid_lines='solid', label='Pays', tick_style = {'font-size': 18})\n",
    "            ax_y = bq.Axis(scale=y_sc, orientation='vertical', grid_lines='solid', label='Valeur', label_offset='-50')\n",
    "            fig = bq.Figure(marks=[bar], axes=[ax_x, ax_y], title=f\"Nombre de relations lexicales dans l'extraction du {np.datetime_as_string(user_choice.value, unit='D')}\", animation_duration = 1000)\n",
    "            \n",
    "            def edit_graph(obj):\n",
    "                choosed_data = data2[data2[\"wiktionaryDumpVersion\"] == user_choice.value]\n",
    "                bar.x = choosed_data[\"observationLanguage\"].values\n",
    "                bar.y = choosed_data[categories].T\n",
    "                fig.title = f\"Nombre de relations lexicales dans l'extraction du {np.datetime_as_string(user_choice.value, unit='D')}\"\n",
    "            \n",
    "        display(user_choice)\n",
    "        user_choice.observe(edit_graph,'value')\n",
    "        display(fig)  \n",
    "        \n",
    "choice.observe(event, 'value')\n",
    "display(choice, out)\n",
    "event(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. dbnaryTranslationsCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbnary-datacube",
   "language": "python",
   "name": "ex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
