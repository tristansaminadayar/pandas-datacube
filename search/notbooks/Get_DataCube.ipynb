{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fd1a46-a6af-4c80-b93e-17cdfe539c9f",
   "metadata": {},
   "source": [
    "### Télécharger des données statistiques de Dbnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b46be415-870b-4c49-9af8-d5dfcbfb9eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Layout, Box, HBox, VBox\n",
    "from IPython.display import Markdown, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ENDPOINT: str = \"http://kaiko.getalp.org/sparql\"   #\"https://statistics.gov.scot/sparql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "72c069ce-79b0-417d-8882-b51085fac0b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load ../../src/SPARQL_query\n",
    "import datetime\n",
    "import time as tm\n",
    "from typing import NoReturn\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from SPARQLWrapper import SPARQLWrapper\n",
    "from ipywidgets import widgets\n",
    "\n",
    "\n",
    "def add_progress_bar(fun: callable):\n",
    "    def function_modif(*args, **kwargs):\n",
    "        progress_bar = widgets.IntProgress(bar_style='success', description='Loading:')\n",
    "        display(progress_bar)\n",
    "        kwargs['widget'] = progress_bar\n",
    "        ret = fun(*args, **kwargs)\n",
    "        progress_bar.close()\n",
    "        return ret\n",
    "\n",
    "    return function_modif\n",
    "\n",
    "\n",
    "class SPARQLquery:\n",
    "    \"\"\"\n",
    "    Class allowing to make a query on a remote SPARQL server, its main characteristics are :\n",
    "     - Taking into account the big answers by concatenating them as they are received\n",
    "     - Ability to access the size of the database\n",
    "     - Ability to retrieve the response in `pandas` data frame format\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, endpoint: str, query: str, verbose: bool = False, step: int = 5000,\n",
    "                 widget: widgets.IntProgress = None) -> NoReturn:\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        :param endpoint: Url to the remote SPARQL service\n",
    "        :param query: The query\n",
    "        :param verbose: If the detail text will be displayed\n",
    "        :param step: The max number of result to receive\n",
    "        \"\"\"\n",
    "        self.sparql = SPARQLWrapper(endpoint)\n",
    "        self.sparql.setReturnFormat(\"json\")\n",
    "\n",
    "        self.query: str = query\n",
    "        self.verbose: bool = verbose\n",
    "        self.step: int = step\n",
    "        self.resultSize: int = self.get_result_size()\n",
    "        self.is_widget: bool = False\n",
    "\n",
    "        if widget:\n",
    "            self.widget = widget\n",
    "            self.widget.max = self.resultSize\n",
    "            self.widget.value = 0\n",
    "            self.is_widget = True\n",
    "\n",
    "    def get_result_size(self) -> int:\n",
    "        \"\"\"\n",
    "        Function return the size of a query (only in SELECT query).\n",
    "        \"\"\"\n",
    "\n",
    "        if self.query.strip().startswith(\"SELECT\") or self.query.strip().startswith(\n",
    "                \"select\"):  # Modifie the query to count the number of answer\n",
    "\n",
    "            if self.verbose:\n",
    "                print(tm.strftime(f\"[%H:%M:%S] Obtention du nombre de résultats avant exécuter la requête\"))\n",
    "\n",
    "            start: int = 7  # We detect the position of the first variable after the select\n",
    "            while self.query[start] != '?':\n",
    "                start += 1\n",
    "            end: int = start\n",
    "            while self.query[end:end + 5] != \"WHERE\" and self.query[end:end + 5] != \"where\":\n",
    "                end += 1\n",
    "\n",
    "            mot: str = self.query[start: end - 1]  # THe name of the variable\n",
    "\n",
    "            self.sparql.setQuery(self.query.replace(mot, f\"(COUNT (*) as ?cnt)\", 1))\n",
    "            processed_results: dict = self.sparql.query().convert()  # Do the query\n",
    "            number_of_results: int = int(processed_results['results']['bindings'][0]['cnt']['value'])\n",
    "\n",
    "            if self.verbose:\n",
    "                print(tm.strftime(f\"[%H:%M:%S] Il y a  {number_of_results} résultats...\"))\n",
    "\n",
    "            return number_of_results\n",
    "        return 1\n",
    "\n",
    "    def get_sparql_dataframe(self, query: str, text: str = \"\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Helper function to convert SPARQL results into a Pandas data frame.\n",
    "\n",
    "        Credit: Douglas Fils\n",
    "\n",
    "        :param query: The query to perform\n",
    "        :param text: optional text to print in verbose mode\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            print(tm.strftime(f\"[%H:%M:%S] Transmission {text} en cours...\"), end='')\n",
    "\n",
    "        self.sparql.setQuery(query)\n",
    "\n",
    "        processed_results: dict = self.sparql.query().convert()\n",
    "\n",
    "        if self.verbose:\n",
    "            print(tm.strftime(f\"\\r[%H:%M:%S] Transmission {text} réussi, conversion en Data Frame...\"), end='')\n",
    "\n",
    "        cols = processed_results['head']['vars']\n",
    "\n",
    "        out = [[row.get(c, {}).get('value') for c in cols] for row in processed_results['results']['bindings']]\n",
    "\n",
    "        if self.is_widget:\n",
    "            if text == \"\":\n",
    "                self.widget.value = self.widget.max\n",
    "            else:\n",
    "                self.widget.value = int(text.split(' ')[0])\n",
    "\n",
    "        if self.verbose:\n",
    "            print(tm.strftime(f\" Effectué\"))\n",
    "\n",
    "        return pd.DataFrame(out, columns=cols)\n",
    "\n",
    "    def do_query(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Performs the query all at once if the result is not too big or little by little otherwise,\n",
    "        if the query is not a selection it will be done all at once.\n",
    "\n",
    "        :return: The result of the query\n",
    "        \"\"\"\n",
    "        if self.resultSize > self.step:\n",
    "            query = self.query + f\" LIMIT {self.step}\"\n",
    "            return pd.concat(\n",
    "                [self.get_sparql_dataframe(query + f\" OFFSET {value}\", f\"{value} sur {self.resultSize}\") for value in\n",
    "                 range(0, self.resultSize, self.step)])\n",
    "        return self.get_sparql_dataframe(self.query)\n",
    "\n",
    "\n",
    "@add_progress_bar\n",
    "def get_datasets(endpoint: str, verbose: bool = False, widget: widgets.IntProgress = None):\n",
    "    \"\"\"\n",
    "    Dbnary specific function;\n",
    "\n",
    "    Get all datasets available names on Dbnary and their description.\n",
    "\n",
    "    :param endpoint: The address of the SPARQL server\n",
    "    :param verbose: If the detail text will be displayed\n",
    "    :param widget: If the detail widget will be displayed\n",
    "    :return: The data frame of all datasets available names and their description\n",
    "    \"\"\"\n",
    "    \"\"\"SELECT ?song ?length {\n",
    "    ?song a :Song .\n",
    "    \n",
    "}\"\"\"\n",
    "    query: str = \"SELECT DISTINCT ?dataset ?commentaire WHERE {?dataset a <http://purl.org/linked-data/cube#DataSet> \\\n",
    "    OPTIONAL {?dataset <http://www.w3.org/2000/01/rdf-schema#comment> ?commentaire}}\"\n",
    "\n",
    "    if verbose:\n",
    "        print(tm.strftime(f\"[%H:%M:%S] Requête au serveur des différents datasets disponible... \"))\n",
    "\n",
    "    list_datasets: pd.DataFrame = SPARQLquery(endpoint, query, verbose=verbose,\n",
    "                                              widget=widget).do_query()  # We recovers all DataSets Structure\n",
    "\n",
    "    if verbose:\n",
    "        print(tm.strftime(f\"[%H:%M:%S] Il y a {len(list_datasets)} datasets disponibles\"))\n",
    "\n",
    "    return list_datasets\n",
    "\n",
    "\n",
    "@add_progress_bar\n",
    "def get_features(endpoint: str, dataset_name: str, widget: widgets.IntProgress = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Dbnary specific function;\n",
    "\n",
    "    Get all features available names on a dataset in Dbnary.\n",
    "\n",
    "    :param endpoint: The address of the SPARQL server\n",
    "    :param dataset_name: The name of the dataset where you want to have its features\n",
    "    :param widget: If the detail widget will be displayed\n",
    "    :return: The data frame of all datasets features names available\n",
    "    \"\"\"\n",
    "    deb: str = \"select ?property where { { select ?item where {?item <http://purl.org/linked-data/cube#dataSet> <\"\n",
    "    fin: str = \"> } LIMIT 1 } ?item ?property ?value . filter ( ?property not in ( rdf:type ) ) }\"\n",
    "    query: str = deb + dataset_name + fin\n",
    "\n",
    "    result: pd.DataFrame = SPARQLquery(endpoint, query, widget=widget).do_query()\n",
    "    return result\n",
    "\n",
    "\n",
    "@add_progress_bar\n",
    "def download_dataset(endpoint: str, dataset_name: str, features_names: list[str],\n",
    "                     widget: widgets.IntProgress = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Dbnary specific function;\n",
    "\n",
    "    Download and return all selected features of a dataset\n",
    "\n",
    "    :param endpoint: The address of the SPARQL server\n",
    "    :param dataset_name: The name of the dataset where you want to download its features\n",
    "    :param features_names: The names of features to download\n",
    "    :param widget: If the detail widget will be displayed\n",
    "    :return: The data frame of selected and downloaded characteristics of a dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # We will build the query\n",
    "    query: str = \"SELECT \"\n",
    "    vars_list: list[str] = [item.split('#')[-1].split('/')[-1] for item in features_names]\n",
    "    query += \" \".join([f\"?{item}\" for item in vars_list])\n",
    "    query += f\" WHERE {'{'} ?o <http://purl.org/linked-data/cube#dataSet> <{dataset_name}> . \"\n",
    "    query += \" \".join([f\"?o <{uri}> ?{name} .\" for uri, name in zip(features_names, vars_list)])\n",
    "    query += \" } \"\n",
    "\n",
    "    # Do the query\n",
    "    return SPARQLquery(endpoint, query, widget=widget).do_query()\n",
    "\n",
    "\n",
    "def transformation_date(date: int) -> datetime.datetime:\n",
    "    if int(date[6:]) == 0:\n",
    "        return datetime.datetime(year=int(date[:4]), month=int(date[4:6]), day=int(date[6:]) + 1)\n",
    "    return datetime.datetime(year=int(date[:4]), month=int(date[4:6]), day=int(date[6:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "849ad8cc-dd1d-4c36-b396-ee6999d21f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, bar_style='success', description='Loading:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Veuillez choisir un DataSet à étudier: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109c2ba5785d48b9894fa5e1ba569b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Box(children=(Dropdown(description='Choix:', layout=Layout(flex='1 3 auto', width='auto'), opti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1898b24594684c569c3efcd68503f2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_datasets = get_datasets(ENDPOINT, verbose = False)\n",
    "list_datasets_short = list_datasets['dataset'].map(lambda x: x.split('/')[-1]).to_frame().join(list_datasets['commentaire'].to_frame())\n",
    "\n",
    "\n",
    "DataFrame = pd.DataFrame()\n",
    "output = widgets.Output()\n",
    "\n",
    "dataset_user_choice = widgets.Dropdown(options = [(name, full_name) for name, full_name in zip(list_datasets_short['dataset'].values.reshape(-1),\n",
    "                                                                                               list_datasets['dataset'].values.reshape(-1))], \n",
    "                                       description=\"Choix:\", layout=Layout(flex='1 3 auto', width='auto'))\n",
    "user_choice_confirm = widgets.Button(description='Soumettre', icon='check', layout=Layout(flex='1 1 auto', width='auto'),\n",
    "                                     tooltip = \"Cliquer ici pour confirmer votre choix\")\n",
    "description = widgets.Label(value=f\"Description: {list_datasets[list_datasets['dataset'] == dataset_user_choice.value]['commentaire'].values[0]}\",\n",
    "                            layout=Layout(flex='1 1 auto', width='auto'))\n",
    "\n",
    "items = [dataset_user_choice, user_choice_confirm]\n",
    "\n",
    "box_layout = Layout(display='flex', flex_flow='row', align_items='stretch', width='90%')\n",
    "                            \n",
    "line_1 = Box(children=items, layout=box_layout)\n",
    "line_2 = Box(children=[description], layout=box_layout)\n",
    "ui = VBox([line_1, line_2])\n",
    "\n",
    "def user_choice_change(obj):\n",
    "    description.value=f\"Description: {list_datasets[list_datasets['dataset'] == dataset_user_choice.value]['commentaire'].values[0]}\"\n",
    "\n",
    "\n",
    "def user_choice_confirm_eventhandler(obj):\n",
    "    choice: str = dataset_user_choice.value\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(choice)\n",
    "        output2 = widgets.Output()\n",
    "        display(Markdown(data=\"#### Les différentes catégories de ce dataset sont: \"))\n",
    "        categories_long = get_features(ENDPOINT, choice)\n",
    "        categories_short = categories_long[\"property\"].map(lambda x: x.split('#')[-1].split('/')[-1]).to_frame()\n",
    "        \n",
    "        display(categories_short)\n",
    "        \n",
    "        select = widgets.SelectMultiple(options=[(name, full_name) for name, full_name in zip(categories_short.values.reshape(-1), categories_long.values.reshape(-1))], \n",
    "                                        description='Critères: ', disabled=False, layout=Layout(flex='1 1 auto', width='auto', height = \"auto\"),\n",
    "                                        style={'description_width': 'initial'})\n",
    "        select_box = Box(children=[select], layout=box_layout)\n",
    "        display(Markdown(\"####  Veuillez choisir au moins deux critères à télécharger:\"))\n",
    "        select_confirm = widgets.Button(description='Soumettre', icon='check', layout=Layout(flex='1 1 auto', width='auto'),\n",
    "                                     tooltip = \"Cliquer ici pour confirmer votre choix\")\n",
    "        select_confirm_box = Box(children=[select_confirm], layout=box_layout)\n",
    "        select_ui = VBox([select_box, select_confirm_box])\n",
    "        \n",
    "        def selection_confirm_eventhandler(obj):\n",
    "            with output2:\n",
    "                if len(select.value) >= 2: # We will constuct the query\n",
    "                    global DataFrame\n",
    "                    clear_output()\n",
    "                    DataFrame = download_dataset(ENDPOINT, choice, select.value)\n",
    "                    display(DataFrame.head())\n",
    "            \n",
    "        select_confirm.on_click(selection_confirm_eventhandler)\n",
    "        display(select_ui, output2)\n",
    "        \n",
    "        \n",
    "user_choice_confirm.on_click(user_choice_confirm_eventhandler)\n",
    "dataset_user_choice.observe(user_choice_change, 'value')\n",
    "\n",
    "display(Markdown(data=\"#### Veuillez choisir un DataSet à étudier: \"))\n",
    "display(ui, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbnary-datacube",
   "language": "python",
   "name": "ex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
