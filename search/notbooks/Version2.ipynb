{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des différentes statistiques de Dbnary\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDF\n",
    "import rdflib\n",
    "\n",
    "# Other\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "#  PLotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction qui retourne un DataFrame des résultats d'une requête SPARQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load ../../src/SPARQL_query\n",
    "import time as tm\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper\n",
    "from typing import NoReturn\n",
    "\n",
    "\n",
    "class SPARQLquery:\n",
    "    \"\"\"\n",
    "    Class allowing to make a query on a remote SPARQL server, its main characteristics are :\n",
    "     - Taking into account the big answers by concatenating them as they are received\n",
    "     - Ability to access the size of the database\n",
    "     - Ability to retrieve the response in `pandas` data frame format\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, endpoint: str, query: str, verbose: bool = False, step: int = 5000) -> NoReturn:\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        :param endpoint: Url to the remote SPARQL service\n",
    "        :param query: The query\n",
    "        :param verbose: If the detail text will be displayed\n",
    "        :param step: The max number of result to receive\n",
    "        \"\"\"\n",
    "        self.sparql = SPARQLWrapper(endpoint)\n",
    "        self.sparql.setReturnFormat(\"json\")\n",
    "\n",
    "        self.query: str = query\n",
    "        self.verbose: bool = verbose\n",
    "        self.step: int = step\n",
    "        self.resultSize: int = self.get_result_size()\n",
    "\n",
    "    def get_result_size(self) -> int:\n",
    "        \"\"\"\n",
    "        Function return the size of a query (only in SELECT query)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.query.strip().startswith(\"SELECT\"):  # Modifie the query to count the number of answer\n",
    "\n",
    "            if self.verbose:\n",
    "                print(tm.strftime(f\"[%H:%M:%S] Obtention du nombre de résultats avant exécuter la requête\"))\n",
    "\n",
    "            start: int = 7  # We detect the position of the first variable after the select\n",
    "            while self.query[start] != '?':\n",
    "                start += 1\n",
    "            end: int = start\n",
    "            while self.query[end] != ' ' and self.query[end] != '\\n':\n",
    "                end += 1\n",
    "\n",
    "            mot: str = self.query[start: end]  # THe name of the variable\n",
    "\n",
    "            self.sparql.setQuery(self.query.replace(mot, f\"(COUNT ({mot}) as ?cnt)\", 1))\n",
    "            processed_results: dict = self.sparql.query().convert()  # Do the query\n",
    "            number_of_results: int = int(processed_results['results']['bindings'][0]['cnt']['value'])\n",
    "\n",
    "            if self.verbose:\n",
    "                print(tm.strftime(f\"[%H:%M:%S] Il y a  {number_of_results} résultats...\"))\n",
    "\n",
    "            return number_of_results\n",
    "        return -1\n",
    "\n",
    "    def get_sparql_dataframe(self, query: str, text: str = \"\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Helper function to convert SPARQL results into a Pandas data frame.\n",
    "\n",
    "        Credit: Douglas Fils\n",
    "\n",
    "        :param query: The query to perform\n",
    "        :param text: optional text to print in verbose mode\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            print(tm.strftime(f\"[%H:%M:%S] Transmission {text} en cours...\"), end='')\n",
    "\n",
    "        self.sparql.setQuery(query)\n",
    "\n",
    "        processed_results: dict = self.sparql.query().convert()\n",
    "\n",
    "        if self.verbose:\n",
    "            print(tm.strftime(f\"\\r[%H:%M:%S] Transmission {text} réussi, conversion en Data Frame...\"), end='')\n",
    "\n",
    "        cols = processed_results['head']['vars']\n",
    "\n",
    "        out = [[row.get(c, {}).get('value') for c in cols] for row in processed_results['results']['bindings']]\n",
    "\n",
    "        if self.verbose:\n",
    "            print(tm.strftime(f\" Effectué\"))\n",
    "\n",
    "        return pd.DataFrame(out, columns=cols)\n",
    "\n",
    "    def do_query(self) -> pd.DataFrame:\n",
    "\n",
    "        if self.resultSize > self.step:\n",
    "            query = self.query + f\" LIMIT {self.step}\"\n",
    "            return pd.concat(\n",
    "                [self.get_sparql_dataframe(query + f\" OFFSET {value}\", f\"{value:6} sur {self.resultSize}\") for value in\n",
    "                 range(0, self.resultSize, self.step)])\n",
    "\n",
    "        return self.get_sparql_dataframe(self.query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On commence par chercher tout les différents types de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:46:20] Requête au serveur des différents datasets disponible... \n",
      "[10:46:20] Obtention du nombre de résultats avant exécuter la requête\n",
      "[10:46:21] Il y a  5 résultats...\n",
      "[10:46:21] Transmission  réussi, conversion en Data Frame... Effectué\n",
      "[10:46:21] Transmission  réussi, conversion en Data Frame... Effectué\n",
      "[10:46:21] Il y a 5 datasets disponibles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dbnaryNymRelationsCube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dbnaryStatisticsCube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dbnaryTranslationsCube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enhancementConfidenceDataCube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>translationGlossesCube</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          values\n",
       "0         dbnaryNymRelationsCube\n",
       "1           dbnaryStatisticsCube\n",
       "2         dbnaryTranslationsCube\n",
       "3  enhancementConfidenceDataCube\n",
       "4         translationGlossesCube"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENDPOINT: str = \"http://kaiko.getalp.org/sparql\"\n",
    "  \n",
    "print(tm.strftime(f\"[%H:%M:%S] Requête au serveur des différents datasets disponible... \"))\n",
    "list_datasets = query = SPARQLquery(ENDPOINT, \"\"\"SELECT DISTINCT ?values WHERE {?values a qb:DataSet }\"\"\", verbose = True).do_query()  # We recovers all DataSets Structure\n",
    "print(tm.strftime(f\"[%H:%M:%S] Il y a {len(list_datasets)} datasets disponibles\"))\n",
    "\n",
    "\n",
    "list_datasets_short = pd.DataFrame(list_datasets['values'].map(lambda x: x.split('/')[-1]))\n",
    "list_datasets_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Veuillez choisir un DataSet à étudier: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e51373d859b49c19690f18f51ea21d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Choix:', layout=Layout(width='50%'), options=(('dbnaryNymRelationsCube', 'http://kaiko.g…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f918ce99e78644efb2a68090eb1412e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Soumettre', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388b4e8c02374ea18929db6f1fe89d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = widgets.Output()\n",
    "dataset_user_choice = widgets.Dropdown(options = [(name, full_name) for name, full_name in zip(list_datasets_short.values.reshape(-1), list_datasets.values.reshape(-1))], description=\"Choix:\", layout=widgets.Layout(width='50%'))\n",
    "user_choice_confirm = widgets.Button(description='Soumettre')\n",
    "\n",
    "def user_choice_confirm_eventhandler(obj):\n",
    "    choice: str = dataset_user_choice.value\n",
    "    with output:\n",
    "        g = rdflib.Graph()\n",
    "        g.parse(choice)\n",
    "\n",
    "        print(g.serialize(format=\"turtle\").decode(\"utf-8\"))\n",
    "\n",
    "user_choice_confirm.on_click(user_choice_confirm_eventhandler)\n",
    "\n",
    "display(Markdown(data=\"#### Veuillez choisir un DataSet à étudier: \"))\n",
    "display(dataset_user_choice)\n",
    "display(user_choice_confirm, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rdflib.namespace import *\n",
    "\n",
    "g = rdflib.Graph()\n",
    "g.parse(\"http://kaiko.getalp.org/dbnary#dbnaryStatisticsDataStructure\", format = 'xml')\n",
    "print(g.serialize(format=\"turtle\").decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql = SPARQLWrapper(\"http://kaiko.getalp.org/sparql/\")\n",
    "sparql.setQuery(\"describe <http://kaiko.getalp.org/dbnary#dbnaryStatisticsDataStructure>\")\n",
    "sparql.setReturnFormat(\"xml\")\n",
    "processed_results: dict = sparql.query().convert()\n",
    "print(processed_results.serialize(format=\"turtle\").decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparql_dataframe(\"http://kaiko.getalp.org/sparql/\", \"describe <nodeID:b10849>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(rdflib.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparql_dataframe(\"http://kaiko.getalp.org/sparql\", \"DESCRIBE <http://kaiko.getalp.org/dbnary#dbnaryStatisticsDataStructure>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataset_user_choice.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri: str = \"http://kaiko.getalp.org/dbnary#dbnaryNymRelationsDataStructure\"\n",
    "g = rdflib.Graph()  # create a Graph\n",
    "result: rdflib.Graph = g.parse(uri, format=\"xml\")  # parse in an RDF file hosted on the Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = g.query(\"\"\"SELECT ?a WHERE {?a a <http://purl.org/linked-data/cube#DataStructureDefinition>}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.serialize(format=\"json\").decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbnary-datacube",
   "language": "python",
   "name": "ex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
