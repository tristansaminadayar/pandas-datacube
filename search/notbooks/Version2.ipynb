{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des différentes statistiques de Dbnary\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RDF\n",
    "import rdflib\n",
    "from rdflib.namespace import *\n",
    "\n",
    "# Data analys \n",
    "import numpy as np\n",
    "\n",
    "#  PLotting\n",
    "import bqplot as bq\n",
    "import bqplot.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from ipywidgets import Layout, Box, HBox, VBox\n",
    "\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datetime\n",
    "\n",
    "ENDPOINT: str = \"http://kaiko.getalp.org/sparql\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction qui retourne un DataFrame des résultats d'une requête SPARQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load ../../src/SPARQL_query\n",
    "import time as tm\n",
    "from typing import NoReturn\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper\n",
    "from ipywidgets import widgets\n",
    "\n",
    "\n",
    "class SPARQLquery:\n",
    "    \"\"\"\n",
    "    Class allowing to make a query on a remote SPARQL server, its main characteristics are :\n",
    "     - Taking into account the big answers by concatenating them as they are received\n",
    "     - Ability to access the size of the database\n",
    "     - Ability to retrieve the response in `pandas` data frame format\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, endpoint: str, query: str, verbose: bool = False, step: int = 1000,\n",
    "                 widget: widgets.IntProgress = None) -> NoReturn:\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        :param endpoint: Url to the remote SPARQL service\n",
    "        :param query: The query\n",
    "        :param verbose: If the detail text will be displayed\n",
    "        :param step: The max number of result to receive\n",
    "        \"\"\"\n",
    "        self.sparql = SPARQLWrapper(endpoint)\n",
    "        self.sparql.setReturnFormat(\"json\")\n",
    "\n",
    "        self.query: str = query\n",
    "        self.verbose: bool = verbose\n",
    "        self.step: int = step\n",
    "        self.resultSize: int = self.get_result_size()\n",
    "        self.is_widget: bool = False\n",
    "\n",
    "        if widget:\n",
    "            self.widget = widget\n",
    "            self.widget.max = self.resultSize\n",
    "            self.widget.value = 0\n",
    "            self.is_widget = True\n",
    "\n",
    "    def get_result_size(self) -> int:\n",
    "        \"\"\"\n",
    "        Function return the size of a query (only in SELECT query)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.query.strip().startswith(\"SELECT\") or self.query.strip().startswith(\n",
    "                \"select\"):  # Modifie the query to count the number of answer\n",
    "\n",
    "            if self.verbose:\n",
    "                print(tm.strftime(f\"[%H:%M:%S] Obtention du nombre de résultats avant exécuter la requête\"))\n",
    "\n",
    "            start: int = 7  # We detect the position of the first variable after the select\n",
    "            while self.query[start] != '?':\n",
    "                start += 1\n",
    "            end: int = start\n",
    "            while self.query[end:end + 5] != \"WHERE\" and self.query[end:end + 5] != \"where\":\n",
    "                end += 1\n",
    "\n",
    "            mot: str = self.query[start: end - 1]  # THe name of the variable\n",
    "\n",
    "            self.sparql.setQuery(self.query.replace(mot, f\"(COUNT (*) as ?cnt)\", 1))\n",
    "            processed_results: dict = self.sparql.query().convert()  # Do the query\n",
    "            number_of_results: int = int(processed_results['results']['bindings'][0]['cnt']['value'])\n",
    "\n",
    "            if self.verbose:\n",
    "                print(tm.strftime(f\"[%H:%M:%S] Il y a  {number_of_results} résultats...\"))\n",
    "\n",
    "            return number_of_results\n",
    "        return 1\n",
    "\n",
    "    def get_sparql_dataframe(self, query: str, text: str = \"\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Helper function to convert SPARQL results into a Pandas data frame.\n",
    "\n",
    "        Credit: Douglas Fils\n",
    "\n",
    "        :param query: The query to perform\n",
    "        :param text: optional text to print in verbose mode\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            print(tm.strftime(f\"[%H:%M:%S] Transmission {text} en cours...\"), end='')\n",
    "\n",
    "        self.sparql.setQuery(query)\n",
    "\n",
    "        processed_results: dict = self.sparql.query().convert()\n",
    "\n",
    "        if self.verbose:\n",
    "            print(tm.strftime(f\"\\r[%H:%M:%S] Transmission {text} réussi, conversion en Data Frame...\"), end='')\n",
    "\n",
    "        cols = processed_results['head']['vars']\n",
    "\n",
    "        out = [[row.get(c, {}).get('value') for c in cols] for row in processed_results['results']['bindings']]\n",
    "\n",
    "        if self.is_widget:\n",
    "            if text == \"\":\n",
    "                self.widget.value = self.widget.max\n",
    "            else:\n",
    "                self.widget.value = int(text.split(' ')[0])\n",
    "\n",
    "        if self.verbose:\n",
    "            print(tm.strftime(f\" Effectué\"))\n",
    "\n",
    "        return pd.DataFrame(out, columns=cols)\n",
    "\n",
    "    def do_query(self) -> pd.DataFrame:\n",
    "\n",
    "        if self.resultSize > self.step:\n",
    "            query = self.query + f\" LIMIT {self.step}\"\n",
    "            return pd.concat(\n",
    "                [self.get_sparql_dataframe(query + f\" OFFSET {value}\", f\"{value} sur {self.resultSize}\") for value in\n",
    "                 range(0, self.resultSize, self.step)])\n",
    "        return self.get_sparql_dataframe(self.query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On commence par chercher tout les différents types de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548b7a6a5628405f97b6ba519ac1f27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, bar_style='success', description='Loading:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>commentaire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dbnaryNymRelationsCube</td>\n",
       "      <td>The Data Cube containing observations on nym r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dbnaryStatisticsCube</td>\n",
       "      <td>The Data Cube containing general observations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dbnaryTranslationsCube</td>\n",
       "      <td>The Data Cube containing observations on trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enhancementConfidenceDataCube</td>\n",
       "      <td>The Data Cube containing the confidence measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>translationGlossesCube</td>\n",
       "      <td>The Data Cube containing observations on gloss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         dataset  \\\n",
       "0         dbnaryNymRelationsCube   \n",
       "1           dbnaryStatisticsCube   \n",
       "2         dbnaryTranslationsCube   \n",
       "3  enhancementConfidenceDataCube   \n",
       "4         translationGlossesCube   \n",
       "\n",
       "                                         commentaire  \n",
       "0  The Data Cube containing observations on nym r...  \n",
       "1  The Data Cube containing general observations ...  \n",
       "2  The Data Cube containing observations on trans...  \n",
       "3  The Data Cube containing the confidence measur...  \n",
       "4  The Data Cube containing observations on gloss...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_datasets(endpoint: str, query: str, verbose: bool = False, widget: widgets.IntProgress = None):\n",
    "    if verbose:\n",
    "        print(tm.strftime(f\"[%H:%M:%S] Requête au serveur des différents datasets disponible... \"))\n",
    "    \n",
    "    list_datasets = SPARQLquery(ENDPOINT, query, verbose=verbose, widget=widget).do_query()  # We recovers all DataSets Structure\n",
    "        \n",
    "    if verbose:    \n",
    "        print(tm.strftime(f\"[%H:%M:%S] Il y a {len(list_datasets)} datasets disponibles\"))\n",
    "        \n",
    "    return list_datasets\n",
    "\n",
    "ui = widgets.IntProgress(bar_style='success', description='Loading:',)\n",
    "display(ui)\n",
    "\n",
    "list_datasets = get_datasets(ENDPOINT, \"\"\"SELECT ?dataset ?commentaire WHERE {?dataset a qb:DataSet ; rdfs:comment ?commentaire}\"\"\", verbose = False, widget = ui)\n",
    "list_datasets_short = list_datasets['dataset'].map(lambda x: x.split('/')[-1]).to_frame().join(list_datasets['commentaire'].to_frame())\n",
    "list_datasets_short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On va proposer à l'utilisateur de choisir quel dataset télécharger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Veuillez choisir un DataSet à étudier: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3b4d80e6bd4abaa9cbef1fda586195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Box(children=(Dropdown(description='Choix:', layout=Layout(flex='1 3 auto', width='auto'), opti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad987e9f75144eb8d2d95ec813dec8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DataFrame = pd.DataFrame()\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "dataset_user_choice = widgets.Dropdown(options = [(name, full_name) for name, full_name in zip(list_datasets_short['dataset'].values.reshape(-1),\n",
    "                                                                                               list_datasets['dataset'].values.reshape(-1))], \n",
    "                                       description=\"Choix:\", layout=Layout(flex='1 3 auto', width='auto'))\n",
    "user_choice_confirm = widgets.Button(description='Soumettre', icon='check', layout=Layout(flex='1 1 auto', width='auto'),\n",
    "                                     tooltip = \"Cliquer ici pour confirmer votre choix\")\n",
    "description = widgets.Label(value=f\"Description: {list_datasets[list_datasets['dataset'] == dataset_user_choice.value]['commentaire'].values[0]}\",\n",
    "                            layout=Layout(flex='1 1 auto', width='auto'))\n",
    "\n",
    "\n",
    "\n",
    "items = [dataset_user_choice, user_choice_confirm]\n",
    "\n",
    "box_layout = Layout(display='flex', flex_flow='row', align_items='stretch', width='90%')\n",
    "\n",
    "                            \n",
    "line_1 = Box(children=items, layout=box_layout)\n",
    "line_2 = Box(children=[description], layout=box_layout)\n",
    "ui = VBox([line_1, line_2])\n",
    "\n",
    "\n",
    "\n",
    "def user_choice_change(obj):\n",
    "    description.value=f\"Description: {list_datasets[list_datasets['dataset'] == dataset_user_choice.value]['commentaire'].values[0]}\"\n",
    "\n",
    "\n",
    "def user_choice_confirm_eventhandler(obj):\n",
    "    choice: str = dataset_user_choice.value\n",
    "    with output:\n",
    "        clear_output()\n",
    "        output2 = widgets.Output()\n",
    "        display(Markdown(data=\"#### Les différentes catégories de ce dataset sont: \"))\n",
    "        progress_bar = widgets.IntProgress(bar_style='success', description='Loading:')\n",
    "        display(progress_bar)\n",
    "        categories_long = SPARQLquery(ENDPOINT, f\"\"\"DESCRIBE ?item WHERE {'{'}?item qb:dataSet <{choice}> {'}'} LIMIT 1\"\"\", \n",
    "                                      verbose = False, widget = progress_bar).do_query()['p'].to_frame(name=None).set_axis([\"Caractéristiques\"], axis=1)\n",
    "        categories_short = pd.DataFrame(categories_long[\"Caractéristiques\"].map(lambda x: x.split('#')[-1]))\n",
    "        progress_bar.close()\n",
    "        \n",
    "        display(categories_short)\n",
    "        \n",
    "        select = widgets.SelectMultiple(options=[(name, full_name) for name, full_name in zip(categories_short.values.reshape(-1), categories_long.values.reshape(-1))], \n",
    "                                        description='Critères: ', disabled=False, layout=Layout(flex='1 1 auto', width='auto', height = \"auto\"),\n",
    "                                        style={'description_width': 'initial'})\n",
    "        select_box = Box(children=[select], layout=box_layout)\n",
    "        display(Markdown(\"####  Veuillez choisir au moins deux critères à télécharger:\"))\n",
    "        select_confirm = widgets.Button(description='Soumettre', icon='check', layout=Layout(flex='1 1 auto', width='auto'),\n",
    "                                     tooltip = \"Cliquer ici pour confirmer votre choix\")\n",
    "        select_confirm_box = Box(children=[select_confirm], layout=box_layout)\n",
    "        select_ui = VBox([select_box, select_confirm_box])\n",
    "        \n",
    "        def selection_confirm_eventhandler(obj):\n",
    "            selection = select.value\n",
    "            with output2:\n",
    "                if len(selection) >= 2: # We will constuct the query\n",
    "                    global DataFrame\n",
    "                    clear_output()\n",
    "                    query: str = \"SELECT \"\n",
    "                    vars_list: list[str] = [item.split('#')[-1] for item in selection]\n",
    "                    for item in vars_list:\n",
    "                        query += f\"?{item} \"\n",
    "                    query += f\"WHERE {'{'} ?o qb:dataSet <{choice}> . \"\n",
    "                    for uri, name in zip(selection, vars_list):\n",
    "                        query += f\"?o <{uri}> ?{name} . \"\n",
    "                    query += \"} \"\n",
    "                    \n",
    "                    progress_bar = widgets.IntProgress(bar_style='success', description='Loading:')\n",
    "                    display(progress_bar)\n",
    "                    DataFrame = SPARQLquery(ENDPOINT, query, widget = progress_bar).do_query()\n",
    "                    progress_bar.close()\n",
    "                    display(DataFrame.head())                 \n",
    "            \n",
    "        select_confirm.on_click(selection_confirm_eventhandler)\n",
    "        display(select_ui, output2)\n",
    "        \n",
    "        \n",
    "user_choice_confirm.on_click(user_choice_confirm_eventhandler)\n",
    "dataset_user_choice.observe(user_choice_change, 'value')\n",
    "\n",
    "display(Markdown(data=\"#### Veuillez choisir un DataSet à étudier: \"))\n",
    "display(ui, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des certains Data set particulier, le code ci-dessous n'est pas généralisable\n",
    "#### 1. dbnaryNymRelationsCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dbnary-datacube\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'count'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-ecb9cd56987a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrelations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nymRelation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrelations\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nymRelation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'wiktionaryDumpVersion'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'observationLanguage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'observationLanguage'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'wiktionaryDumpVersion'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dbnary-datacube\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dbnary-datacube\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'count'"
     ]
    }
   ],
   "source": [
    "DataFrame['count'] = DataFrame['count'].astype(int)\n",
    "\n",
    "relations = DataFrame['nymRelation'].unique()\n",
    "labels = [item.split('#')[-1] for item in relations]\n",
    "data = DataFrame.pivot_table(columns='nymRelation', index = ['wiktionaryDumpVersion', 'observationLanguage'], aggfunc=lambda x: max(x)).reset_index().sort_values(by='observationLanguage').sort_values(by='wiktionaryDumpVersion')\n",
    "\n",
    "def transformation_date(date: int) -> datetime.datetime:\n",
    "    if int(date[6:]) == 0:\n",
    "        return datetime.datetime(year=int(date[:4]), month=int(date[4:6]), day=int(date[6:]) + 1)\n",
    "    return datetime.datetime(year=int(date[:4]), month=int(date[4:6]), day=int(date[6:]))\n",
    "\n",
    "data[\"wiktionaryDumpVersion\"] = data[\"wiktionaryDumpVersion\"].map(transformation_date)\n",
    "\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "choice = widgets.ToggleButtons(options=[('Statistiques globales', 'glob'), ('Par pays', 'pays')],  description='Choix:',\n",
    "    disabled=False,\n",
    "    tooltips=['Statistiques de tout les pays par années', 'Statistiques d\\' pays au cours du temps']\n",
    ")\n",
    "\n",
    "\n",
    "def event(obj):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        if choice.value == \"pays\":\n",
    "            user_choice = widgets.Dropdown(options = list(data[\"observationLanguage\"].unique()), description=\"Choix:\")\n",
    "\n",
    "            choosed_data = data[data[\"observationLanguage\"] == user_choice.value]\n",
    "\n",
    "            y_sc = bq.LinearScale()\n",
    "            x_ord = bq.scales.DateScale()\n",
    "            \n",
    "            line = bq.Lines(x=choosed_data[\"wiktionaryDumpVersion\"] , y=choosed_data[\"count\"][relations].T, stroke_width=1, display_legend=True, labels= labels, scales={'x': x_ord, 'y': y_sc})\n",
    "            ax_x = bq.Axis(scale=x_ord, grid_lines='solid', label='Date', tick_format = '%m %Y')\n",
    "            ax_y = bq.Axis(scale=y_sc, orientation='vertical', grid_lines='solid', label='Valeur', label_offset='-50')\n",
    "            fig = bq.Figure(marks=[line], axes=[ax_x, ax_y], title=f\"Différentes relations lexicales dans l'extraction {user_choice.value}\", animation_duration = 1000)\n",
    "\n",
    "            def edit_graph(obj):\n",
    "                choosed_data = data[data[\"observationLanguage\"] == user_choice.value]\n",
    "                line.y = choosed_data[\"count\"][relations].T\n",
    "                line.x = choosed_data[\"wiktionaryDumpVersion\"]\n",
    "                fig.title = f\"Différentes relations lexicales dans l'extraction {user_choice.value}\"\n",
    "            \n",
    "        if choice.value == \"glob\":\n",
    "            user_choice = widgets.Dropdown(options = [(np.datetime_as_string(item, unit='D'), item) for item in data[\"wiktionaryDumpVersion\"].unique()], description=\"Choix:\", value = max(data[\"wiktionaryDumpVersion\"].unique()))\n",
    "            \n",
    "            x_ord = bq.OrdinalScale()\n",
    "            y_sc = bq.LinearScale()\n",
    "            \n",
    "            choosed_data = data[data[\"wiktionaryDumpVersion\"] == user_choice.value]\n",
    "            \n",
    "            x = choosed_data[\"observationLanguage\"].values\n",
    "            y = choosed_data[\"count\"][relations].T\n",
    "            \n",
    "            bar = bq.Bars(x=x, y=y, scales={'x': x_ord, 'y':y_sc}, type='stacked', labels = labels, color_mode = 'element', display_legend=True,  colors =[\"red\", \"blue\", \"cyan\", \"pink\", \"lime\", \"purple\", \"orange\", \"brown\"])\n",
    "            ax_x = bq.Axis(scale=x_ord, grid_lines='solid', label='Pays')\n",
    "            ax_y = bq.Axis(scale=y_sc, orientation='vertical', grid_lines='solid', label='Valeur', label_offset='-50')\n",
    "            fig = bq.Figure(marks=[bar], axes=[ax_x, ax_y], title=f\"Nombre de relations lexicales dans l'extraction du {np.datetime_as_string(user_choice.value, unit='D')}\", animation_duration = 1000)\n",
    "            \n",
    "            def edit_graph(obj):\n",
    "                choosed_data = data[data[\"wiktionaryDumpVersion\"] == user_choice.value]\n",
    "                bar.x = choosed_data[\"observationLanguage\"].values\n",
    "                bar.y = choosed_data[\"count\"][relations].T\n",
    "                fig.title = f\"Nombre de relations lexicales dans l'extraction du {np.datetime_as_string(user_choice.value, unit='D')}\"\n",
    "            \n",
    "        display(user_choice)\n",
    "        user_choice.observe(edit_graph,'value')\n",
    "        display(fig)  \n",
    "    \n",
    "choice.observe(event, 'value')\n",
    "display(choice, out)\n",
    "event(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. dbnaryStatisticsCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0fbbd5e6274d70ad2b08de097345ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Choix:', options=(('Statistiques globales', 'glob'), ('Par pays', 'pays')), tooltip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b9e73b5a7a4a6a809ab95d04e521b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = DataFrame.sort_values(by='wiktionaryDumpVersion')\n",
    "data[[\"translationsCount\", \"lexicalEntryCount\", \"lexicalSenseCount\", \"pageCount\"]] = data[[\"translationsCount\", \"lexicalEntryCount\", \"lexicalSenseCount\", \"pageCount\"]].astype(int)\n",
    "\n",
    "def transformation_date(date: int) -> datetime.datetime:\n",
    "    if int(date[6:]) == 0:\n",
    "        return datetime.datetime(year=int(date[:4]), month=int(date[4:6]), day=int(date[6:]) + 1)\n",
    "    return datetime.datetime(year=int(date[:4]), month=int(date[4:6]), day=int(date[6:]))\n",
    "\n",
    "data[\"wiktionaryDumpVersion\"] = data[\"wiktionaryDumpVersion\"].map(transformation_date)\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "choice = widgets.ToggleButtons(options=[('Statistiques globales', 'glob'), ('Par pays', 'pays')],  description='Choix:',\n",
    "    disabled=False,\n",
    "    tooltips=['Statistiques de tout les pays par années', 'Statistiques d\\' pays au cours du temps']\n",
    ")\n",
    "\n",
    "categories = [\"lexicalEntryCount\", \"translationsCount\", \"lexicalSenseCount\", \"pageCount\"]\n",
    "\n",
    "def event(obj):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        if choice.value == \"pays\":\n",
    "            user_choice = widgets.Dropdown(options = list(data[\"observationLanguage\"].unique()), description=\"Choix:\")\n",
    "\n",
    "            choosed_data = data[data[\"observationLanguage\"] == user_choice.value]\n",
    "\n",
    "            y_sc = bq.LinearScale()\n",
    "            x_ord = bq.scales.DateScale()\n",
    "\n",
    "            line = bq.Lines(x=choosed_data[\"wiktionaryDumpVersion\"] , y=choosed_data[categories].T, stroke_width=1, display_legend=True, labels=categories, scales={'x': x_ord, 'y': y_sc})\n",
    "            ax_x = bq.Axis(scale=x_ord, grid_lines='solid', label='Date', tick_format = '%m %Y')\n",
    "            ax_y = bq.Axis(scale=y_sc, orientation='vertical', grid_lines='solid', label='Valeur', label_offset='-50')\n",
    "            fig = bq.Figure(marks=[line], axes=[ax_x, ax_y], title=f\"Nombre d'éléments dans l'extraction {user_choice.value}\", animation_duration = 1000)\n",
    "\n",
    "            def edit_graph(obj):\n",
    "                choosed_data = data[data[\"observationLanguage\"] == user_choice.value]\n",
    "                line.y = choosed_data[categories].T\n",
    "                line.x = choosed_data[\"wiktionaryDumpVersion\"]\n",
    "                \n",
    "        if choice.value == \"glob\":\n",
    "            user_choice = widgets.Dropdown(options = [(np.datetime_as_string(item, unit='D'), item) for item in data[\"wiktionaryDumpVersion\"].unique()], description=\"Choix:\", value = max(data[\"wiktionaryDumpVersion\"].unique()))\n",
    "            \n",
    "            x_ord = bq.OrdinalScale()\n",
    "            y_sc = bq.LinearScale()\n",
    "            \n",
    "            choosed_data = data[data[\"wiktionaryDumpVersion\"] == user_choice.value]\n",
    "            \n",
    "            x = choosed_data[\"observationLanguage\"].values\n",
    "            y = choosed_data[categories].T\n",
    "            \n",
    "            bar = bq.Bars(x=x, y=y, scales={'x': x_ord, 'y':y_sc}, type='stacked', labels = categories, color_mode = 'element', display_legend=True,  colors =[\"red\", \"blue\", \"cyan\", \"pink\", \"lime\", \"purple\", \"orange\", \"brown\"])\n",
    "            ax_x = bq.Axis(scale=x_ord, grid_lines='solid', label='Pays')\n",
    "            ax_y = bq.Axis(scale=y_sc, orientation='vertical', grid_lines='solid', label='Valeur', label_offset='-50')\n",
    "            fig = bq.Figure(marks=[bar], axes=[ax_x, ax_y], title=f\"Nombre de relations lexicales dans l'extraction du {np.datetime_as_string(user_choice.value, unit='D')}\", animation_duration = 1000)\n",
    "            \n",
    "            def edit_graph(obj):\n",
    "                choosed_data = data[data[\"wiktionaryDumpVersion\"] == user_choice.value]\n",
    "                bar.x = choosed_data[\"observationLanguage\"].values\n",
    "                bar.y = choosed_data[categories].T\n",
    "                fig.title = f\"Nombre de relations lexicales dans l'extraction du {np.datetime_as_string(user_choice.value, unit='D')}\"\n",
    "            \n",
    "        display(user_choice)\n",
    "        user_choice.observe(edit_graph,'value')\n",
    "        display(fig)  \n",
    "        \n",
    "choice.observe(event, 'value')\n",
    "display(choice, out)\n",
    "event(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbnary-datacube",
   "language": "python",
   "name": "ex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
